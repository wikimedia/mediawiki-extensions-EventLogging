#!/usr/bin/env python
# -*- coding: utf8 -*-
from __future__ import unicode_literals

import calendar
import hashlib
import logging
import operator
import os
import sys
import time

import jsonschema
import zmq

if sys.version_info[0] >= 3:
    items = operator.methodcaller('items')
    from urllib.parse import parse_qsl
    from urllib.request import urlopen
else:
    items = operator.methodcaller('iteritems')
    from urlparse import parse_qsl
    from urllib2 import urlopen

json = zmq.utils.jsonapi  # gets best available json lib


ENDPOINT = b'tcp://*:8484'
META_SCHEMA_REV = 4891798

logging.basicConfig(level=logging.DEBUG, stream=sys.stderr)

# Salt value for hashing IPs. Because this value is generated at
# runtime, IPs cannot be compared across restarts, but it spares us
# having to secure a config file.
salt = os.urandom(16)

# Maps compressed query param name of auto fields to human-readable
# name. I hate this because it veers off the path of explicitly modelled
# data and back toward the land of ad-hoc customizations. But the
# expansion of the max URL length to 1024 bytes will allow us to send
# raw URL-encoded JSON instead of key=val params, which will resolve
# some of this.
meta_readable = {
    '_rv': '_revision',
    '_id': '_schema',
    '_ok': '_valid',
    '_db': '_site'
}

url = 'http://meta.wikimedia.org/w/index.php?action=raw&oldid=%d'

schemas = {}  # Local cache


# Maps JSON schema types to a function that will convert a string to
# that type. Ugly. Also going away when we move to URL-encoded JSON.
casters = {
    'integer': int,
    'array': lambda x: x.split(','),
    'boolean': lambda x: x.lower() == 'true',
    'null': lambda x: None,
    'number': lambda x: float(x) if '.' in x else int(x),
    'string': lambda x: x
}


def typecast(obj, schema):
    """
    Optimistically attempt to cast the value of each property to the
    type specified for that property by the schema.
    """
    properties = schema.get('properties', {})
    types = {k: v.get('type') for k, v in items(properties)}
    return {k: casters[types.get(k, 'string')](v) for k, v in items(obj)}


def parse_meta(object):
    metaschema = get_schema(META_SCHEMA_REV)
    return typecast(object, metaschema)


def decode_event(q):
    """
    Decodes a query string generated by EventLogging to a Python object
    by matching it with a schema and validating it accordingly.
    """
    q = dict(parse_qsl(q.strip('?;')))
    meta = {}
    e = {}
    for k, v in items(q):
        if k.startswith('_'):
            meta[k] = v
        else:
            e[k] = v
    meta = parse_meta(meta)

    schema = get_schema(meta['_rv'])
    e = typecast(e, schema)
    jsonschema.validate(e, schema)

    e['meta'] = {meta_readable.get(k, k): v for k, v in items(meta)}
    return e


def parse_ncsa_ts(ts):
    """Converts a timestamp in NCSA format to seconds since epoch."""
    return calendar.timegm(time.strptime(ts, '%Y-%m-%dT%H:%M:%S'))


def hash_value(s):
    """Produce a salted SHA1 hash of any string value."""
    hash = hashlib.sha1(s)
    hash.update(salt)
    return hash.hexdigest()


def parse_bits_line(line):
    """Parse a log line emitted by varnishncsa on the bits hosts."""
    try:
        q, origin, seq_id, timestamp, client_ip = line.split()
        e = decode_event(q)
    except (ValueError, KeyError, jsonschema.ValidationError):
        logging.exception('Unable to decode: %s', line)
        return None

    e['meta'].update({
        'truncated': not q.endswith(';'),
        'origin': origin.split('.', 1)[0],
        'seqId': int(seq_id),
        'timestamp': parse_ncsa_ts(timestamp),
        'clientIp': hash_value(client_ip)
    })

    return e


def get_schema(rev_id):
    """Get schema from memory or HTTP."""
    schema = schemas.get(rev_id)
    if schema is None:
        schema = http_get_schema(rev_id)
        if schema is not None:
            schemas[rev_id] = schema
    return schema


def http_get_schema(rev_id):
    """Retrieve schema via HTTP."""
    req = urlopen(url % rev_id)
    content = req.read().decode('utf8')
    try:
        schema = json.loads(content)
        assert isinstance(schema, dict)
    except:
        logging.exception('Failed to decode HTTP response: %s', content)
        return None
    return schema


def iter_loglines():
    context = zmq.Context.instance()
    sock = context.socket(zmq.SUB)
    sock.connect(b'tcp://localhost:8422')
    sock.setsockopt(zmq.SUBSCRIBE, b'')
    while 1:
        yield sock.recv_unicode()


def iter_events():
    for e in iter_loglines():
        e = parse_bits_line(e)
        if e is not None:
            yield e


if __name__ == '__main__':
    context = zmq.Context.instance()
    pub = context.socket(zmq.PUB)
    pub.bind(ENDPOINT)

    logging.info('Publishing JSON events on %s..', ENDPOINT.decode('utf8'))

    for event in iter_events():
        pub.send_unicode(json.dumps(event) + '\n')
