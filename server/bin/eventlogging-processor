#!/usr/bin/env python -OO
# -*- coding: utf-8 -*-
"""
  eventlogging-processor
  -----------------------------
  Transform raw log stream to JSON event stream

  usage: eventlogging-processor [-h] [--sid SID] format \
              input output [output ...]

  positional arguments:
    format      Format string
    input       URI of raw input stream
    output      URIs of output streams

  optional arguments:
    -h, --help  show this help message and exit
    --sid SID   set input socket identity
    --output-invalid  URI of stream which to send invalid events

  formatters:
     %h         Client IP
     %j         JSON object
     %q         Query-string-encoded JSON
     %t         Timestamp in NCSA format.

  :copyright: (c) 2012 by Ori Livneh <ori@wikimedia.org>
  :license: GNU General Public Licence 2.0 or later

"""
from __future__ import unicode_literals

import sys
reload(sys)
sys.setdefaultencoding('utf-8')

import argparse
import logging

from eventlogging import (capsule_uuid, create_event_error, LogParser,
                          get_reader, get_writer, validate, setup_logging,
                          uri_force_raw, uri_append_query_items)

from jsonschema import ValidationError

setup_logging()

ap = argparse.ArgumentParser(description='Raw log -> JSON stream',
                             fromfile_prefix_chars='@')
ap.add_argument('format', help='Format string')
# Read in raw events.  This keeps the reader
# attempting to parse the input as json.
ap.add_argument('input', help='URI of raw input stream', type=uri_force_raw)
ap.add_argument('output', nargs='+', help='URIs of output streams')
ap.add_argument(
    '--sid',
    help='Set ZeroMQ/Kafka identity. '
    'Only use this if your input URI starts with tcp:// or kafka://'
)
ap.add_argument(
    '--output-invalid',
    const=True,
    default=False,
    nargs='?',
    action='store',
    help='URI of output stream for invalid events. '
    'If this is given without a value, the first of the output URIs will be '
    'used to write invalid events.  Invalid events are written using the '
    'EventError schema.'
)
args = ap.parse_args()

parser = LogParser(args.format)

writers_list = []
for output_uri in args.output:
    writers_list.append(get_writer(output_uri))
    logging.info('Publishing valid JSON events to %s.', output_uri)

if args.output_invalid:
    # If --output-invalid was supplied without a value,
    # use the same writer for both invalid and valid events.
    if args.output_invalid is True:
        args.output_invalid = args.output[0]
        writer_invalid = writers_list[0]
    else:
        writer_invalid = get_writer(args.output_invalid)

    logging.info('Publishing invalid raw events to %s.', args.output_invalid)
else:
    writer_invalid = None

if args.sid:
    args.input = uri_append_query_items(args.input, {'identity': args.sid})


def write_event_error(writer, raw_event, error_message, error_code):
    try:
        event_error = create_event_error(raw_event, error_message, error_code)
    except Exception as e:
        logging.error('Unable to create EventError object: %s' % e.message)
    writer.send(event_error)

for raw_event in get_reader(args.input):
    try:
        event = parser.parse(raw_event)
        event.pop('clientValidated', None)
        event.pop('isTruncated', None)
        validate(event)
        event['uuid'] = capsule_uuid(event)

    except ValidationError as e:
        logging.error('Unable to validate: %s (%s)', raw_event, e.message)
        if writer_invalid:
            write_event_error(
                writer_invalid, raw_event, e.message, 'validation'
            )

    except Exception as e:
        logging.error('Unable to process: %s (%s)', raw_event, e.message)
        if writer_invalid:
            write_event_error(
                writer_invalid, raw_event, e.message, 'processor'
            )

    else:
        for w in writers_list:
            w.send(event)
